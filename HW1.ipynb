{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2520a2af",
   "metadata": {},
   "source": [
    "# HW1--Group 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ec1831",
   "metadata": {},
   "source": [
    "kaidx@kth.se & zhenlinz@kth.se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724db621",
   "metadata": {},
   "source": [
    "Task\n",
    "\n",
    "You are to implement the stages of finding textually similar documents based on Jaccard similarity using the shingling, minhashing, and locality-sensitive hashing (LSH) techniques and corresponding algorithms. The implementation can be done using any big data processing framework, such as Apache Spark, Apache Flink, or no framework, e.g., in Java, Python, etc. To test and evaluate your implementation, write a program that uses your implementation to find similar documents in a corpus of 5-10 or more documents such as web pages or emails.\n",
    "\n",
    "The stages should be implemented as a collection of classes, modules, functions or procedures depending the framework and the language of your choice. Below, we give a description of sample classes that implement different stages of finding textually similar documents. You do not have to develop the exact same classes and data types as described below. Feel free to use data structures that suit you best.\n",
    "\n",
    "A class Shingling that constructs k–shingles of a given length k (e.g., 10) from a given document, computes a hash value for each unique shingle, and represents the document in the form of an ordered set of its hashed k-shingles.\n",
    "A class CompareSets that computes the Jaccard similarity of two sets of integers – two sets of hashed shingles.\n",
    "A class MinHashing that builds a minHash signature (in the form of a vector or a set) of a given length n from a given set of integers (a set of hashed shingles).\n",
    "A class CompareSignatures that estimates similarity of two integer vectors – minhash signatures – as a fraction of components, in which they agree.\n",
    "(Optional task for extra 2 bonus) A class LSH that implements the LSH technique: given a collection of minhash signatures (integer vectors) and a similarity threshold t, the LSH class (using banding and hashing) finds candidate pairs of signatures agreeing on at least fraction t of their components.\n",
    "To test and evaluate scalability (the execution time versus the size of input dataset) of your implementation, write a program that uses your classes to find similar documents in a corpus of 5-10 documents. Choose a similarity threshold s (e.g., 0,8) that states that two documents are similar if the Jaccard similarity of their shingle sets is at least s. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e96f8cf",
   "metadata": {},
   "source": [
    "## Method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e49942a",
   "metadata": {},
   "source": [
    "The classes will be implemented as Python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f090cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import re\n",
    "import hashlib\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce014e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-7203135641490933748,\n",
       " -6829267605805752621,\n",
       " -6789454011174268007,\n",
       " -5314113622642457652,\n",
       " 1846648366803520841,\n",
       " 3764021740757154572,\n",
       " 5510198638609846826,\n",
       " 7766216449880686841,\n",
       " 7937168720576788187}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Produces shingles for a given text\n",
    "def shingling(text, k = 2, trim = True):\n",
    "    # possibly trim text\n",
    "    s = re.sub('[\\s+]', '', text) if trim else text\n",
    "\n",
    "    # produce k-shingles and map shingles to shingle IDs using hash()\n",
    "    shingles = {s[i:i + k] for i in range(len(s) - k + 1)}\n",
    "\n",
    "    hashes = {hash(i) for i in shingles}\n",
    "    return hashes\n",
    "\n",
    "shingling('this is a test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f66d0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2777777777777778"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jaccard similarity for two sets\n",
    "def compareSets(setA, setB):\n",
    "    return len(setA.intersection(setB)) / len(setA.union(setB))\n",
    "\n",
    "setA = shingling(\"how a nice day\")\n",
    "setB = shingling(\"how are you today\")   \n",
    "compareSets(setA,setB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49a1eec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[219999983789596839455493963522010816285621917997982337728748363806,\n",
       " 786029126074746716785257545659415459959373297086359467808737391442417822872533524452325780086190622096529910810679,\n",
       " 96609120577086375298743731262274850804746671092,\n",
       " 739447016452013557224137849509649045762804072342963900350319380697770104018983805860444208251749111574960191449942,\n",
       " 544160981907356457025152255781454962744522988923040286164550473851952564720437732416913380372922424205801295132170464868319316527416494754097377706132217,\n",
       " 257143993503011867438328337594533942392054373348456406114793506630835581506266203690509609270240802972794584883388028729430648287514865798529194676021374,\n",
       " 5802550165512709507798071956094618899,\n",
       " 2577106736418456394883600353311571602503213823261646351324035266051,\n",
       " 7054476718490182837319462295996750530494891886941439033417043717052545500770,\n",
       " 6158646141371861958515262949898497505037837514861641271148312992369511551549,\n",
       " 8813572437020963652366833482765243315477319745014089719187519536741136846794,\n",
       " 155989972188581118862090315689018648327126139053185478679638310156820934815359211461582910430967186267155348207589694682046867512030094037874382390398155]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates the Minhash signature of length n from the shingle set\n",
    "algorithms = [x for x in hashlib.algorithms_guaranteed if x not in [\"shake_128\", \"shake_256\"]] \n",
    "# they need a fixed-length argument(The shake_128() and shake_256() algorithms provide variable length digests with length_in_bits//2 up to 128 or 256 bits of security)\n",
    "\n",
    "#hash a str into 8 digits using hash functions (hexdigest returns a HEX string representing the hash)\n",
    "def hashWith(alg, i):\n",
    "    return int(hashlib.new(alg,str(i).encode('UTF-8')).hexdigest(), 16)\n",
    "\n",
    "def minHashing(shingleSet, n = 3):\n",
    "    # throw error if not enough hash functions are available\n",
    "    if (n > len(algorithms)):\n",
    "        raise ValueError('The maximum number of hash functions available is {0}.'.format(len(algorithms)))\n",
    "\n",
    "    # iterate over n hash functions and compute h_min(s) for the set.\n",
    "    signature = [min(hashWith(alg, i) for i in shingleSet) for alg in algorithms[0:n]] \n",
    "    return signature\n",
    "\n",
    "setA = shingling(\"how a nice day\")\n",
    "signature = minHashing(setA, 12)\n",
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dafa3b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set A {-8957301752865267865, -5314113622642457652, -5028587291202181997, 2173489992638392465, -8118833194662279372, -3975535657283062222, 8627203540232068210, 8543914300129337426, -4663268017958072006, 4669754365558314877}\n",
      "Set B {-8957301752865267865, -3900540923561869556, -7318321795911401232, 2173489992638392465, -3975535657283062222, -5028587291202181997, 8543914300129337426, -3458459600085340353, 4669754365558314877}\n",
      "0.46153846153846156\n",
      "Signature A [6520479235281335633732565341848356552193568697630085883070274962889, 17017145237257462087502244632711186712093825247196702372993562845503565907549234481412773509850810899809629959147, 23933812262506906556674202667015514511725239228, 3538233692629721733900047907022889781413722926232651745202099931117925028623720703380524972647088548190346087420102, 473230387848900049273495312219113081299628786841411392929781455532182393470792600866902715562691112119283644722463962866248410941841983935975585007979126, 2544740743276742494608420289651120936428464395760716484376162640502162112237877169452849190721830189766122165144062549001267771661144095093432351964555566, 187578529022744236517681357807582860124, 612108479274304231770939349950880642254068981011697657106912351453, 20898559619155385361452277777371823160332739301323732942792578706278382626446, 14645303673220556233670492392112259239322550487012438386053118957751375640409, 14225708491924945337048815541598573382701723527793175153286382935395398773132, 591601930244985673284221053048838951162244760293862670448998684630794811262428267489914932319746056381155358840118975525996970188486223945447141632110076]\n",
      "Signature B [219999983789596839455493963522010816285621917997982337728748363806, 1287948416589159858123630443283073154863865143367512502156243885445028045193414032752051399853340752945149104306880, 23933812262506906556674202667015514511725239228, 3370479830847190029032559311047958070782871521353237559484669810950617727487919350941350227507603900258396743179734, 473230387848900049273495312219113081299628786841411392929781455532182393470792600866902715562691112119283644722463962866248410941841983935975585007979126, 891048684201875235887179075816762793549586303443132788665913934026888082820188846796265310339500484969791654429874715493904560253803037776068083470011223, 51245805145709717093942240957042989656, 612108479274304231770939349950880642254068981011697657106912351453, 20898559619155385361452277777371823160332739301323732942792578706278382626446, 24330216918923351881825939031959425267386622372189888664673458335917302961069, 14225708491924945337048815541598573382701723527793175153286382935395398773132, 591601930244985673284221053048838951162244760293862670448998684630794811262428267489914932319746056381155358840118975525996970188486223945447141632110076]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the signatures, the returned probability will approximate the jaccard similarity of the original shingle sets\n",
    "def compareSignatures(signatureA, signatureB):\n",
    "    if (len(signatureA) != len(signatureB)):\n",
    "        raise ValueError('The signatures have different length({0}, {1} respectively) and should not be compared!', len(signatureA), len(signatureB))\n",
    "\n",
    "    A = np.array(signatureA)\n",
    "    B = np.array(signatureB)\n",
    "    count = np.count_nonzero(A==B)\n",
    "    # Important: Not jaccard similarity -> Probability instead (number_of_same/number_of_total)\n",
    "    probability = count / len(signatureA)\n",
    "    #print(A==B, count, probability)\n",
    "    \n",
    "    return probability\n",
    "\n",
    "setA = shingling(\"what about you\")\n",
    "setB = shingling(\"how about you\")\n",
    "print(\"Set A\", setA)\n",
    "print(\"Set B\", setB)\n",
    "similarity = compareSets(setA, setB)\n",
    "print(similarity)\n",
    "signatureA = minHashing(setA, 12)\n",
    "signatureB = minHashing(setB, 12)\n",
    "print(\"Signature A\", signatureA)\n",
    "print(\"Signature B\", signatureB)\n",
    "compareSignatures(signatureA, signatureB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0328a2bb",
   "metadata": {},
   "source": [
    "The difference between the results of Jaccard similarity and Probability here is about 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e77e55c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('index 1', 'index 0')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Locality sensitive hashing , input parameter: # of bands to separate the signatures into\n",
    "def lhs(signatures, similarity_threshold, nr_bands = 5, nr_buckets = 5):\n",
    "    if (len(signatures) < 1 or not all(len(s) == len(signatures[0]) for s in signatures)):\n",
    "        raise ValueError('The signatures need to have all the same length and be non empty.')\n",
    "\n",
    "    # 1.) Iterate over signatures, cut in bands and hash each band into a bucket\n",
    "    buckets = [set() for x in range(0, nr_buckets)]\n",
    "    bands = np.linspace(0, len(signatures[0]), nr_bands).astype(int).tolist()\n",
    "\n",
    "    for index, signature in enumerate(signatures):\n",
    "        for i in range(0, nr_bands-1):\n",
    "            band_start = bands[i]\n",
    "            band_end = bands[i+1]\n",
    "            # join band to be hashed \"as one entity\"\n",
    "            band = \"\".join(str(x) for x in signature[band_start:band_end])\n",
    "            bucket = hash(band) % nr_buckets\n",
    "            # add the signature-set-join (\"identifier\") to the bucket\n",
    "            #buckets[bucket].add(\"\".join(str(x) for x in signature)) # store stringified signature\n",
    "            buckets[bucket].add(\"index %s\" % index) # replaced above line with a human readable string in order to validate results after\n",
    "    \n",
    "    # 2.) Use sets of buckets to determine candidate pairs based on threshold \n",
    "    relevant_buckets = [x for x in buckets if len(x) >= 2] # only check buckets with more than one signature       \n",
    "    relevant_pairs = []\n",
    "    for bucket in relevant_buckets:\n",
    "        # get all relevant pairs from all buckets and append to a huge list\n",
    "        pairs = [x for x in itertools.combinations(bucket, 2) if x[0] != x[1]]\n",
    "        relevant_pairs += pairs\n",
    "\n",
    "    count = Counter(relevant_pairs)\n",
    "    # count the occourences of each pair in a list and see if the pairs similarity (based on same hashed buckets) crossed the threshold\n",
    "    indices = [index for index, x in enumerate(count.values()) if (x/(nr_bands-1)) >= similarity_threshold] \n",
    "    \n",
    "    # use the indices for the final candidate pairs\n",
    "    candidate_pairs = [pair for index, pair in enumerate(count.keys()) if index in indices]\n",
    "\n",
    "    return candidate_pairs\n",
    "\n",
    "print(lhs([signatureA, signatureB], 0.3))\n",
    "print(lhs([signatureA, signatureB], 0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45de8751",
   "metadata": {},
   "source": [
    "#  Dataset and method implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f3398",
   "metadata": {},
   "source": [
    "We use the Eco-Hotel review dataset, which provides a corpus of 401 text-reviews as csv data and it contains one comment per line. Here we use defined functions on our dataset to find similar comments. Shingling size of 4 is chosen because commnents are short documents with a few lines of content (average character count is around 270).\n",
    "Also, the function compare() is defined to help Jaccard similarity calculation. Threshold values are updated to keep a reasonable number of similar items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7227164d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg char count 268.6708229426434\n",
      "[(73, 74, 1.0),\n",
      " (90, 186, 0.4090909090909091),\n",
      " (90, 194, 0.3235294117647059),\n",
      " (102, 140, 0.3492063492063492),\n",
      " (153, 154, 1.0),\n",
      " (178, 241, 0.375),\n",
      " (178, 395, 0.3333333333333333),\n",
      " (235, 347, 0.34146341463414637),\n",
      " (239, 258, 0.34285714285714286),\n",
      " (239, 347, 0.3333333333333333),\n",
      " (241, 395, 0.30303030303030304),\n",
      " (258, 320, 0.34285714285714286),\n",
      " (258, 347, 0.34375),\n",
      " (258, 351, 0.3055555555555556),\n",
      " (258, 366, 0.3783783783783784),\n",
      " (320, 328, 0.34615384615384615),\n",
      " (320, 330, 0.3055555555555556),\n",
      " (320, 347, 0.3333333333333333),\n",
      " (320, 377, 0.3055555555555556),\n",
      " (320, 382, 0.32075471698113206),\n",
      " (330, 377, 0.3142857142857143)]\n",
      "[(6, 102, 0.4166666666666667),\n",
      " (6, 124, 0.5),\n",
      " (6, 130, 0.4166666666666667),\n",
      " (10, 88, 0.4166666666666667),\n",
      " (10, 124, 0.4166666666666667),\n",
      " (10, 194, 0.4166666666666667),\n",
      " (10, 364, 0.4166666666666667),\n",
      " (11, 97, 0.4166666666666667),\n",
      " (11, 151, 0.4166666666666667),\n",
      " (11, 239, 0.4166666666666667),\n",
      " (11, 258, 0.4166666666666667),\n",
      " (11, 347, 0.4166666666666667),\n",
      " (11, 366, 0.4166666666666667),\n",
      " (12, 336, 0.4166666666666667),\n",
      " (13, 392, 0.5),\n",
      " (55, 65, 0.4166666666666667),\n",
      " (73, 74, 1.0),\n",
      " (88, 253, 0.4166666666666667),\n",
      " (90, 186, 0.6666666666666666),\n",
      " (90, 194, 0.5833333333333334),\n",
      " (95, 97, 0.5),\n",
      " (97, 138, 0.4166666666666667),\n",
      " (97, 151, 0.4166666666666667),\n",
      " (97, 239, 0.4166666666666667),\n",
      " (97, 258, 0.4166666666666667),\n",
      " (97, 334, 0.5833333333333334),\n",
      " (97, 347, 0.4166666666666667),\n",
      " (97, 366, 0.4166666666666667),\n",
      " (99, 151, 0.4166666666666667),\n",
      " (99, 239, 0.4166666666666667),\n",
      " (99, 347, 0.4166666666666667),\n",
      " (112, 397, 0.5),\n",
      " (124, 130, 0.5833333333333334),\n",
      " (124, 134, 0.4166666666666667),\n",
      " (124, 146, 0.4166666666666667),\n",
      " (124, 186, 0.4166666666666667),\n",
      " (124, 194, 0.4166666666666667),\n",
      " (130, 146, 0.4166666666666667),\n",
      " (131, 173, 0.4166666666666667),\n",
      " (134, 146, 0.5),\n",
      " (134, 186, 0.5),\n",
      " (134, 194, 0.4166666666666667),\n",
      " (138, 334, 0.4166666666666667),\n",
      " (146, 186, 0.5),\n",
      " (146, 194, 0.4166666666666667),\n",
      " (146, 248, 0.5),\n",
      " (146, 380, 0.4166666666666667),\n",
      " (149, 340, 0.4166666666666667),\n",
      " (151, 235, 0.4166666666666667),\n",
      " (151, 239, 0.5833333333333334),\n",
      " (151, 258, 0.5),\n",
      " (151, 320, 0.4166666666666667),\n",
      " (151, 347, 0.5833333333333334),\n",
      " (151, 366, 0.5),\n",
      " (153, 154, 1.0),\n",
      " (177, 321, 0.4166666666666667),\n",
      " (178, 241, 0.5833333333333334),\n",
      " (178, 355, 0.4166666666666667),\n",
      " (180, 189, 0.4166666666666667),\n",
      " (183, 238, 0.4166666666666667),\n",
      " (186, 194, 0.4166666666666667),\n",
      " (210, 333, 0.4166666666666667),\n",
      " (229, 246, 0.4166666666666667),\n",
      " (235, 239, 0.4166666666666667),\n",
      " (235, 347, 0.5),\n",
      " (239, 258, 0.5833333333333334),\n",
      " (239, 320, 0.4166666666666667),\n",
      " (239, 347, 0.6666666666666666),\n",
      " (239, 366, 0.5),\n",
      " (241, 355, 0.4166666666666667),\n",
      " (241, 395, 0.4166666666666667),\n",
      " (258, 347, 0.5),\n",
      " (258, 351, 0.4166666666666667),\n",
      " (258, 366, 0.5833333333333334),\n",
      " (320, 328, 0.4166666666666667),\n",
      " (330, 380, 0.5),\n",
      " (347, 366, 0.5)]\n",
      "[('index 176', 'index 266'),\n",
      " ('index 73', 'index 72'),\n",
      " ('index 44', 'index 139'),\n",
      " ('index 37', 'index 109'),\n",
      " ('index 27', 'index 250'),\n",
      " ('index 98', 'index 68'),\n",
      " ('index 153', 'index 152'),\n",
      " ('index 400', 'index 150'),\n",
      " ('index 170', 'index 284'),\n",
      " ('index 187', 'index 386'),\n",
      " ('index 167', 'index 377'),\n",
      " ('index 327', 'index 360'),\n",
      " ('index 97', 'index 115'),\n",
      " ('index 239', 'index 140'),\n",
      " ('index 162', 'index 131'),\n",
      " ('index 338', 'index 202'),\n",
      " ('index 311', 'index 286'),\n",
      " ('index 134', 'index 358'),\n",
      " ('index 87', 'index 53'),\n",
      " ('index 39', 'index 117'),\n",
      " ('index 251', 'index 255'),\n",
      " ('index 307', 'index 252'),\n",
      " ('index 18', 'index 217'),\n",
      " ('index 389', 'index 340'),\n",
      " ('index 396', 'index 230'),\n",
      " ('index 54', 'index 123'),\n",
      " ('index 33', 'index 132'),\n",
      " ('index 376', 'index 248'),\n",
      " ('index 333', 'index 348'),\n",
      " ('index 206', 'index 47')]\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "from pprint import pprint\n",
    "\n",
    "# Import hotel review data\n",
    "f = codecs.open('data.txt', encoding='utf-8')\n",
    "dataSet = [line.strip() for line in f]\n",
    "\n",
    "print('avg char count', sum(len(d) for d in dataSet)/len(dataSet))\n",
    "\n",
    "# Executes given comparison function over combinations of elements in input array\n",
    "def compare(fn, arr):\n",
    "    return [(s[0][0], s[1][0], fn(s[0][1], s[1][1])) for s in itertools.combinations(arr, 2)]\n",
    "\n",
    "# jaccard similarity with shinglings\n",
    "shinglings = [(i+1, shingling(t, k=4)) for i, t in enumerate(dataSet)] # value i+1 is the line number and it is stored to evalute results\n",
    "similarities = compare(compareSets, shinglings)\n",
    "\n",
    "similarities = [s for s in similarities if s[2] > 0.3]\n",
    "pprint(similarities)\n",
    "\n",
    "# jaccard similarity with minHashing\n",
    "signatures = [(i, minHashing(s, n=12)) for i, s in shinglings]\n",
    "similarities = compare(compareSignatures, signatures)\n",
    "\n",
    "similarities = [s for s in similarities if s[2] > 0.4]\n",
    "pprint(similarities)\n",
    "\n",
    "# local sensitive hashing\n",
    "pprint(lhs([s for i, s in signatures], 0.5, nr_bands = 4, nr_buckets=200)) # index i represents the comment with line number i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf096ea",
   "metadata": {},
   "source": [
    "We can see that the results of Jaccard similarity with shingling and min hashing are similar. While result of LSH is slightly different due to low number of bands. There are 12 hashing algorithms used for Min Hashing, we use highest vector size of 12. They are split into 4 bands with 3 rows per band.\n",
    "\n",
    "We can see that pairs with Jaccard similarity of 1.0 are identical. If we check the review dataset we can see that comments on line 73 and 153 are the same. \n",
    "\n",
    "We can also check Pair(90, 186) in the reviews file, which is found both in shingling and min hashing method, and we can see that comments are very similar.\n",
    "\n",
    "Line 90: \"We will come back\"\n",
    "\n",
    "Line 186: \"I will come back, thank you.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2d08cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
